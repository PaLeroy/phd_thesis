@inproceedings{saifullah2022deep,
   title = "Deep reinforcement learning-based life-cycle management of deteriorating transportation systems",
    author = "M. Saifullah and C.P. Andriotis and K.G. Papakonstantinou and S.M. Stoffels",
    year = "2022",
    booktitle = "Bridge Safety, Maintenance, Management, Life-Cycle, Resilience and Sustainability",
}

@article{schneider2017reliability,
  title={Reliability analysis and updating of deteriorating systems with subset simulation},
  author={Schneider, Ronald and Th{\"o}ns, Sebastian and Straub, Daniel},
  journal={Structural Safety},
   
   
  year={2017},
  publisher={Elsevier}
}

@techreport{jonkman2010offshore,
  title={{Offshore code comparison collaboration (OC3) for IEA Wind Task 23 offshore wind technology and deployment}},
  author={Jonkman, Jason and Musial, Walter},
  year={2010},
  institution={National Renewable Energy Lab.(NREL), Golden, CO (United States)}
}

@book{Ditlevsen2007StructuralMethods,
  title={Structural reliability methods},
  author={Ditlevsen, Ove and Madsen, Henrik O.},
   
  year={1996},
  publisher={Wiley New York}
}


@article{hlaing2022inspection,
  title={{Inspection and maintenance planning for offshore wind structural components: integrating fatigue failure criteria with Bayesian networks and Markov decision processes}},
  author={Hlaing, Nandar and Morato, Pablo G and Nielsen, Jannie S and Amirafshari, Peyman and Kolios, Athanasios and Rigo, Philippe},
  journal={Structure and Infrastructure Engineering},
   
   
   
  year={2022},
  publisher={Taylor \& Francis}
}

@article{dnv2015probabilistic,
title = {Probabilistic methods for planning of inspection for fatigue cracks in offshore structures},
author = {Inge Lotsberg and Gudfinnur Sigurdsson and Arne Fjeldstad and Torgeir Moan},
journal = {Marine Structures},
 
 
year = {2016},
}

@article{williams1991function,
  title={Function optimization using connectionist reinforcement learning algorithms},
  author={Williams, Ronald J and Peng, Jing},
  journal={Connection Science},
  year={1991},
  publisher={Taylor \& Francis}
}


@article{bolland2024behind,
  title={Behind the Myth of Exploration in Policy Gradients},
  author={Bolland, Adrien and Lambrechts, Gaspard and Ernst, Damien},
  journal={ arXiv:2402.00162},
  year={2024}
}

@article{barlow1984computing,
  title={Computing k-out-of-n system reliability},
  author={Barlow, Richard E and Heidtmann, Klaus D},
  journal={IEEE Transactions on Reliability},
   
  year={1984},
  publisher={IEEE}
}

@article{openai2019dota,
  title={Dota 2 with Large Scale Deep Reinforcement Learning},
  author={OpenAI and Christopher Berner and Greg Brockman and Brooke Chan and Vicki Cheung and Przemys\l{}aw ``Psyho"~D\k{e}biak and Christy Dennison and David Farhi and Quirin Fischer and Shariq Hashme and Chris Hesse and Rafal J\'{o}zefowicz and Scott Gray and Catherine Olsson and Jakub Pachocki and Michael Petrov and Henrique Pond√© de Oliveira Pinto and Jonathan Raiman and Tim Salimans and Jeremy Schlatter and Jonas Schneider and Szymon Sidor and Ilya Sutskever and Jie Tang and Filip Wolski and Susan Zhang},
  year={2019},
  journal={arXiv:1912.06680},
}

@article{akkaya2019solving,
  title={Solving rubik's cube with a robot hand},
  author={Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
  journal={arXiv:1910.07113},
  year={2019}
}

@inproceedings{mcinerney2018explore,
  title={Explore, exploit, and explain: personalizing explainable recommendations with bandits},
  author={McInerney, James and Lacker, Benjamin and Hansen, Samantha and Higley, Karl and Bouchard, Hugues and Gruson, Alois and Mehrotra, Rishabh},
  booktitle={Proceedings of the 12th ACM conference on recommender systems},
   
  year={2018}
}

@article{miotto2018deep,
  title={Deep learning for healthcare: review, opportunities and challenges},
  author={Miotto, Riccardo and Wang, Fei and Wang, Shuang and Jiang, Xiaoqian and Dudley, Joel T},
  journal={Briefings in bioinformatics},
   
   
  year={2018},
  publisher={Oxford University Press}
}

@book{prince2023understanding,
 author = "Simon J.D. Prince",
 title = "Understanding Deep Learning",
 publisher = "MIT Press",
 year = 2023,
}

@inproceedings{rihab_standard_coop,
 author = {Gorsane, Rihab and Mahjoub, Omayma and de Kock, Ruan John and Dubb, Roland and Singh, Siddarth and Pretorius, Arnu},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  
 publisher = {Curran Associates, Inc.},
 title = {Towards a Standardised Performance Evaluation Protocol for Cooperative MARL},
  
 year = {2022}
}


@article{lyu2023centralized,
  title={On centralized critics in multi-agent reinforcement learning},
  author={Lyu, Xueguang and Baisero, Andrea and Xiao, Yuchen and Daley, Brett and Amato, Christopher},
  journal={Journal of Artificial Intelligence Research},
   
   
  year={2023}
}


@article{oliehoek2008optimal,
  title={Optimal and approximate Q-value functions for decentralized POMDPs},
  author={Oliehoek, Frans A and Spaan, Matthijs TJ and Vlassis, Nikos},
  journal={Journal of Artificial Intelligence Research},
   
   
  year={2008}
}

@misc{fombellida2020master,
  title={Master's Thesis: Coordination on the battlefield by multi-agent reinforcement learning.},
  author={Fombellida-Lopez, Arnaud},
  year={2020},
  school={Universit{\'e} de Li{\`e}ge, Li{\`e}ge, Belgique}
}


@article{foerster2016learning,
  title={Learning to communicate with deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Assael, Ioannis Alexandros and De Freitas, Nando and Whiteson, Shimon},
  journal={Advances in neural information processing systems},
   
  year={2016}
}


@article{kiran2021deep,
title={Deep reinforcement learning for autonomous driving: A survey},
author={Kiran, B Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Al Sallab, Ahmad A. and Yogamani, Senthil and P{\'e}rez, Patrick},
journal={IEEE Transactions on Intelligent Transportation Systems},
 
 
 
year={2021},
publisher={IEEE}
}

@inproceedings{xu2017end,
  title={End-to-end learning of driving models from large-scale video datasets},
  author={Xu, Huazhe and Gao, Yang and Yu, Fisher and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
   
  year={2017}
}

@article{gorsane2022towards,
  title={Towards a standardised performance evaluation protocol for cooperative marl},
  author={Gorsane, Rihab and Mahjoub, Omayma and de Kock, Ruan John and Dubb, Roland and Singh, Siddarth and Pretorius, Arnu},
  journal={Advances in Neural Information Processing Systems},
   
   
  year={2022}
}

@incollection{Nowe2012GTMARL,
author="Now{\'e}, Ann
and Vrancx, Peter
and De Hauwere, Yann-Micha{\"e}l",
editor="Wiering, Marco
and van Otterlo, Martijn",
title="Game Theory and Multi-agent Reinforcement Learning",
bookTitle="Reinforcement Learning: State-of-the-Art",
year="2012",
publisher="Springer Berlin Heidelberg",
}



@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={International conference on machine learning},
   
  year={2014},
  organization={Pmlr}
}


@inproceedings{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  booktitle={International conference on learning representations (ICLR)},
  year={2015}
}

@article{bernstein2002complexity,
  title={The complexity of decentralized control of Markov decision processes},
  author={Bernstein, Daniel S and Givan, Robert and Immerman, Neil and Zilberstein, Shlomo},
  journal={Mathematics of operations research},
   
   
   
  year={2002},
  publisher={INFORMS}
}

@inproceedings{lyu2021contrasting,
author = {Lyu, Xueguang and Xiao, Yuchen and Daley, Brett and Amato, Christopher},
title = {Contrasting Centralized and Decentralized Critics in Multi-Agent Reinforcement Learning},
year = {2021},
booktitle = {Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems},
}


@article{openaigym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {{OpenAI Gym}},
  Year = {2016},
  journal = {arXiv:1606.01540},
}

@article{liang2018rllib,
  title = 	 {{RL}lib: Abstractions for Distributed Reinforcement Learning},
  author =       {Liang, Eric and Liaw, Richard and Nishihara, Robert and Moritz, Philipp and Fox, Roy and Goldberg, Ken and Gonzalez, Joseph and Jordan, Michael and Stoica, Ion},
  journal = 	 {Proceedings of the 35th International Conference on Machine Learning},
   
  year = 	 {2018},
   
  publisher =    {PMLR},
}

@article{oroojlooy2022review,
  title={A review of cooperative multi-agent deep reinforcement learning},
  author={Oroojlooy, Afshin and Hajinezhad, Davood},
  journal={Applied Intelligence},
   
   
   
  year={2023},
  publisher={Springer}
}


@inproceedings{giro2022inspection,
  title={Inspection and Maintenance Planning for Offshore Wind Support Structures: Modelling Reliability and Inspection Costs at the System Level},
  author={Giro, Felipe and Mishael, Jose and Morato, Pablo G. and Rigo, Philippe},
  booktitle={International Conference on Offshore Mechanics and Arctic Engineering},
   
  year={2022},

}

@article{Andriotis2019ManagingLearning,
    title = {{Managing engineering systems with large state and action spaces through deep reinforcement learning}},
    year = {2019},
    journal = {Reliability Engineering \& System Safety},
    author = {Andriotis, Charalampos P. and Papakonstantinou, Konstantinos G.},
     
     
    publisher = {Elsevier Ltd},
}

@article{andriotis2021deep,
title = {Deep reinforcement learning driven inspection and maintenance planning under incomplete information and constraints},
journal = {Reliability Engineering \& System Safety},
 
 
year = {2021},
author = {Charalampos P. Andriotis and Konstantinos G. Papakonstantinou},
}

@article{Kostas_MOMDP_POMDP,
    title = {{POMDP and MOMDP solutions for structural life-cycle cost minimization under partial and mixed observability}},
    year = {2018},
    journal = {Structure and Infrastructure Engineering},
    author = {Papakonstantinou, Konstantinos G. and Andriotis, Charalampos P. and Shinozuka, Masanobu},
     
     
     
}

@article{Bismut2019OptimalDete,
  title={Optimal adaptive inspection and maintenance planning for deteriorating structural systems},
  author={Bismut, Elizabeth and Straub, Daniel},
  journal={Reliability Engineering \& System Safety},
   
   
  year={2021},
  publisher={Elsevier}
}


@article{LuqueDBN2019,
    title = {{Risk-based optimal inspection strategies for structural systems using dynamic Bayesian networks}},
    year = {2019},
    journal = {Structural Safety},
    author = {Luque, Jesus and Straub, Daniel},
     
     
    publisher = {Elsevier},
}

@article{Nielsen2014,
    title = {{Methods for risk-based planning of O{\&}M of wind turbines}},
    year = {2014},
    journal = {Energies},
    author = {Nielsen, Jannie S√∏nderk√¶r and S{\o}rensen, John Dalsgaard},
     
     
     
}

@article{Faber2005,
    title = {{Field Implementation of RBI for Jacket Structures}},
    year = {2005},
    journal = {Journal of Offshore Mechanics and Arctic Engineering},
    author = {Faber, Michael Havbro and S√∏"rensen, John D. and Tychsen, Jesper and Straub, Daniel},
     
     
     
}

@article{FaberRBIsummary,
    title = {{An Introduction to Risk Based Inspection}},
    year = {2002},
    journal = {Structural Engineering International: Journal of the International Association for Bridge and Structural Engineering (IABSE)},
    author = {Faber, Michael H.},
}

@article{Papakonstantinou2014Part1,
    title = {{Planning structural inspection and maintenance policies via dynamic programming and Markov processes. Part I: Theory}},
    year = {2014},
    journal = {Reliability Engineering \& System Safety},
    author = {Papakonstantinou, Konstantinos G. and Shinozuka, Masanobu},
    publisher = {Elsevier},
}

@article{Papakonstantinou2014Part2,
    title = {{Planning structural inspection and maintenance policies via dynamic programming and Markov processes. Part II: POMDP implementation}},
    year = {2014},
    journal = {Reliability Engineering \& System Safety},
    author = {Papakonstantinou, Konstantinos G. and Shinozuka, Masanobu},
     
     
    publisher = {Elsevier},
}

@article{morato2022optimal,
  title={{Optimal inspection and maintenance planning for deteriorating structural components through dynamic Bayesian networks and Markov decision processes}},
  author={Morato, Pablo G. and Papakonstantinou, Konstantinos G. and Andriotis, Charalampos P. and Nielsen, Jannie S{\o}nderk{\ae}r and Rigo, Philippe},
  journal={Structural Safety},
   
   
  year={2022},
  publisher={Elsevier},
}

@article{morato2022syst,
title = {Inference and dynamic decision-making for deteriorating systems with probabilistic dependencies through Bayesian networks and deep reinforcement learning},
journal = {Reliability Engineering \& System Safety},
 
 
year = {2023},
author = {Pablo G. Morato and Charalampos P. Andriotis and Konstantinos G. Papakonstantinou and Philippe Rigo}
}

@article{sabatelli2018deepQV,
  title={Deep quality-value ({D}{Q}{V}) learning},
  author={Sabatelli, Matthia and Louppe, Gilles and Geurts, Pierre and Wiering, Marco A},
  journal={Advances in Neural Information Processing Systems, Deep Reinforcement Learning Workshop},
  year={2018}
}

@article{brown1951iterative,
  title={Iterative solution of games by fictitious play},
  author={Brown, George W},
  journal={Act. Anal. Prod Allocation},
   
   
   
  year={1951}
}

@article{Oliehoek_2008,
	year = 2008,
	month = {may},
	publisher = {{AI} Access Foundation},
	 
	 
	author = {Frans A. Oliehoek and Matthijs T. J. Spaan and Nikos Vlassis},
	title = {Optimal and approximate {Q}-value functions for decentralized {POMDPs}},
	journal = {Journal of Artificial Intelligence Research}
}

@article{KRAEMER201682,
title = {Multi-agent reinforcement learning as a rehearsal for decentralized planning},
journal = {Neurocomputing},
 
 
year = {2016},
author = {Landon Kraemer and Bikramjit Banerjee},
}

@article{lowe2017multi,
 author = {Lowe, Ryan and WU, YI and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
 journal = {Advances in Neural Information Processing Systems (NIPS)},
 title = {Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  
 year = {2017}
}


@inproceedings{baudin2022fictitious,
  title={Fictitious Play and Best-Response Dynamics in Identical Interest and Zero-Sum Stochastic Games},
  author={Baudin, Lucas and Laraki, Rida},
  booktitle={International Conference on Machine Learning},
   
  year={2022},
  organization={PMLR}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={IEEE/RSJ international conference on intelligent robots and systems},
   
  year={2012},
}

@article{degrave2022magnetic,
  title={Magnetic control of tokamak plasmas through deep reinforcement learning},
  author={Degrave, Jonas and Felici, Federico and Buchli, Jonas and Neunert, Michael and Tracey, Brendan and Carpanese, Francesco and Ewalds, Timo and Hafner, Roland and Abdolmaleki, Abbas and de las Casas, Diego and Donner, Craig and Fritz, Leslie and Galperti, Cristian and Huber, Andrea and Keeling, James and Tsimpoukelli, Maria and Kay, Jackie and Merle, Antoine and Moret, Jean-Marc and Noury, Seb and Pesamosca, Federico and Pfau, David and Sauter, Olivier and Sommariva, Cristian and Coda, Stefano and Duval, Basil and Fasoli, Ambrogio and Kohli, Pushmeet and Kavukcuoglu, Koray and Hassabis, Demis and Riedmiller, Martin},
  journal={Nature},
   
   
   
  year={2022},
  publisher={Nature Publishing Group}
}

@inproceedings{hansen2004dynamic,
  title={Dynamic programming for partially observable stochastic games},
  author={Hansen, Eric A and Bernstein, Daniel S and Zilberstein, Shlomo},
  booktitle={AAAI},
   
   
  year={2004}
}

@inproceedings{ellis2023smacv2,
    title={{SMAC}v2: An Improved Benchmark for Cooperative Multi-Agent Reinforcement Learning},
    author={Benjamin Ellis and Jonathan Cook and Skander Moalla and Mikayel Samvelyan and Mingfei Sun and Anuj Mahajan and Jakob Nicolaus Foerster and Shimon Whiteson},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
    year={2023},
}

@inproceedings{wang2016dueling,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle={International conference on machine learning},
   
  year={2016},
  publisher = {PMLR},
}


@inproceedings{phan2020learning,
  title={Learning and testing resilience in cooperative multi-agent systems},
  author={Phan, Thomy and Gabor, Thomas and Sedlmeier, Andreas and Ritz, Fabian and Kempter, Bernhard and Klein, Cornel and Sauer, Horst and Schmid, Reiner and Wieghardt, Jan and Zeller, Marc and others},
  booktitle={Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
   
  year={2020}
}
@article{tian2022multi,
  title={Multi-agent Actor-Critic with Time Dynamical Opponent Model},
  author={Tian, Yuan and Kladny, Klaus-Rudolf and Wang, Qin and Huang, Zhiwu and Fink, Olga},

  year={2022}
}

@inproceedings{NIPS2017_3323fe11,
 author = {Lanctot, Marc and Zambaldi, Vinicius and Gruslys, Audrunas and Lazaridou, Angeliki and Tuyls, Karl and Perolat, Julien and Silver, David and Graepel, Thore},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning},
 year = {2017}
}

@article{cornelisse2024humancompatible,
  title={Human-compatible driving partners through data-regularized self-play reinforcement learning},
  author={Daphne Cornelisse and Eugene Vinitsky},
  year={2024},
  journal={arXiv:2403.19648}
}

@article{nocturne2022,
  author  = {Vinitsky, Eugene and Lichtl√©, Nathan and Yang, Xiaomeng and Amos, Brandon and Foerster, Jakob},
  journal = {arXiv:2206.09889},
  title   = {{Nocturne: a scalable driving benchmark for bringing multi-agent learning one step closer to the real world}},
  year    = {2022}
}
@inproceedings{
Muller2020A,
title={A Generalized Training Approach for Multiagent Learning},
author={Paul Muller and Shayegan Omidshafiei and Mark Rowland and Karl Tuyls and Julien Perolat and Siqi Liu and Daniel Hennes and Luke Marris and Marc Lanctot and Edward Hughes and Zhe Wang and Guy Lever and Nicolas Heess and Thore Graepel and Remi Munos},
booktitle={International Conference on Learning Representations},
year={2020},
}



@InProceedings{pmlr-v37-heinrich15,
  title = 	 {Fictitious Self-Play in Extensive-Form Games},
  author = 	 {Heinrich, Johannes and Lanctot, Marc and Silver, David},
  booktitle =  {Proceedings of the 32nd International Conference on Machine Learning},
  year = 	 {2015},
   
}


@article{
avalos2023local,
title={Local Advantage Networks for Multi-Agent Reinforcement Learning in {D}ec-{POMDP}s},
author={Rapha{\"e}l Avalos and Mathieu Reymond and Ann Now{\'e} and Diederik M Roijers},
journal={Transactions on Machine Learning Research},
year={2023},
}

@article{kuba2021trust,
  title={Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning},
  author={Kuba, Jakub Grudzien and Chen, Ruiqing and Wen, Muning and Wen, Ying and Sun, Fanglei and Wang, Jun and Yang, Yaodong},
  journal={International Conference on Learning Representations},
  year={2021}
}



@article{peng2021facmac,
 author = {Peng, Bei and Rashid, Tabish and Schroeder de Witt, Christian and Kamienny, Pierre-Alexandre and Torr, Philip and Boehmer, Wendelin and Whiteson, Shimon},
 journal = {Advances in Neural Information Processing Systems (NeurIPS)},
 title = {{FACMAC}: Factored Multi-Agent Centralised Policy Gradients},
 year = {2021}
}


@article{Du2019LIIRLearning,
  title={{LIIR}: Learning individual intrinsic reward in multi-agent reinforcement learning},
  author={Du, Yali and Han, Lei and Fang, Meng and Liu, Ji and Dai, Tianhong and Tao, Dacheng},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}

@inproceedings{boutilier1996planning,
  title={Planning, learning and coordination in multiagent decision processes},
  author={Boutilier, Craig},
  booktitle={Proceedings of the 6th conference on Theoretical aspects of rationality and knowledge},
  year={1996}
}


@article{foerster2017coma,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob N and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2018}
}


@article{watkins1992q,
  title={{Q}-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  year={1992},
  publisher={Springer}
}


@article{Mnih2015,
    title = {{Human-level control through deep reinforcement learning}},
    year = {2015},
    journal = {Nature},
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
}

@article{stochasticGames,
author = {L. S. Shapley },
title = {Stochastic Games},
journal = {Proceedings of the National Academy of Sciences},
 
 
 
year = {1953},
}


@book{von1947theory,
  title={Theory of games and economic behavior},
  author={Von Neumann, John and Morgenstern, Oskar},
  year={1944},
  publisher={Princeton University Press}
}


 @book{pml1Book,
 author = "Kevin P. Murphy",
 title = "Probabilistic machine learning: an introduction",
 publisher = "MIT Press",
 year = 2022,
}

@book{marl-book,
  author = {Stefano V. Albrecht and Filippos Christianos and Lukas Sch\"afer},
  title = {Multi-Agent Reinforcement Learning: Foundations and Modern Approaches},
  publisher = {MIT Press},
  year = {2023},
}

@article{introDeepRL,
year = {2018},
 
journal = {Foundations and Trends{\textregistered} in Machine Learning},
title = {An Introduction to Deep Reinforcement Learning},
 
 
author = {Vincent Fran{\c{c}}ois{-}Lavet and Peter Henderson and Riashat Islam and Marc G. Bellemare and Joelle Pineau}
}

@article{bellman1966dynamic,
  title={Dynamic programming},
  author={Bellman, Richard},
  journal={Science},
   
   
   
  year={1966},
  publisher={American Association for the Advancement of Science}
}


@article{moerland2023model,
  title={Model-based reinforcement learning: A survey},
  author={Moerland, Thomas M and Broekens, Joost and Plaat, Aske and Jonker, Catholijn M and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
   
   
   
  year={2023},
  publisher={Now Publishers, Inc.}
}


@book{BusoniuErnstBook,
	AUTHOR = {Bu{\c{s}}oniu, Lucian and Babu{\v{s}}ka, Robert and De Schutter, Bart and Ernst, Damien},
	TITLE = {Reinforcement learning and dynamic programming using function approximators},
	YEAR = {2010},
	PUBLISHER = {CRC Press},
}

@book{sutton2018reinforcement,
  title={Reinforcement learning, second edition: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@book{russel2010,
  author = {Russell, Stuart and Norvig, Peter},
  title = {Artificial Intelligence: A Modern Approach},
  publisher = {Prentice Hall},
  year = 2010
}

@book{zhang2023dive,
    title={Dive into Deep Learning},
    author={Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
    publisher={Cambridge University Press},
    year={2023}
}

@article{franccois2018introduction,
title={An introduction to deep reinforcement learning},
  author={Fran{\c{c}}ois-Lavet, Vincent and Henderson, Peter and Islam, Riashat and Bellemare, Marc G and Pineau, Joelle and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
   
   
   
  year={2018},
  publisher={Now Publishers, Inc.}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
   
   
   
  year={2015},
  publisher={Nature Publishing Group}
}

@article{schmidhuber2015deep,
  title={Deep learning in neural networks: An overview},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural networks},
   
   
  year={2015},
  publisher={Elsevier}
}

@inproceedings{sabatelli2020deep,
  title={The deep quality-value family of deep reinforcement learning algorithms},
  author={Sabatelli, Matthia and Louppe, Gilles and Geurts, Pierre and Wiering, Marco A},
  booktitle={International Joint Conference on Neural Networks (IJCNN)},
  year={2020}
}

@inproceedings{he2016opponent,
  title={Opponent modeling in deep reinforcement learning},
  author={He, He and Boyd-Graber, Jordan and Kwok, Kevin and Daum{\'e} III, Hal},
  booktitle={International conference on machine learning},
  year={2016},
  organization={PMLR}
}

@inproceedings{sunehag2018vdn,
  title={Value-Decomposition Networks For Cooperative Multi-Agent Learning Based On Team Reward},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  booktitle={Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
  year={2018}
}


@inproceedings{foerster2017lola,
author = {Foerster, Jakob and Chen, Richard Y. and Al-Shedivat, Maruan and Whiteson, Shimon and Abbeel, Pieter and Mordatch, Igor},
title = {Learning with Opponent-Learning Awareness},
year = {2018},
booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems}
}

@inproceedings{kunz2022multiagent,
  title={A Multiagent CyberBattleSim for RL Cyber Operation Agents},
  author={Kunz, Thomas and Fisher, Christian and La Novara-Gsell, James and Nguyen, Christopher and Li, Li},
  booktitle={2022 International Conference on Computational Science and Computational Intelligence (CSCI)},
  year={2022},
  organization={IEEE}
}


@inproceedings{wiering2005qv,
  title={{QV($\lambda$)-learning}: A new on-policy reinforcement learning algrithm},
  author={Wiering, Marco A},
  booktitle={Proceedings of the 7th European Workshop on Reinforcement Learning},
   
  year={2005}
}


@inproceedings{wiering2009qv,
  title={The {QV} family compared to other reinforcement learning algorithms},
  author={Wiering, Marco A and Van Hasselt, Hado},
  booktitle={2009 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning},
   
  year={2009},
  organization={IEEE}
}

@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
   
   
  year={1992},
  publisher={Springer}
}



@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{bou2023torchrl,
title={Torch{RL}: A data-driven decision-making library for PyTorch},
author={Albert Bou and Matteo Bettini and Sebastian Dittert and Vikash Kumar and Shagun Sodhani and Xiaomeng Yang and Gianni De Fabritiis and Vincent Moens},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@inproceedings{resnick2018pommerman,
  title={PommerMan: A multi-agent playground},
  author={Resnick, Cinjon and Eldridge, Wes and Ha, David and Britz, Denny and Foerster, Jakob and Togelius, Julian and Cho, Kyunghyun and Bruna, Joan},
  booktitle={CEUR Workshop Proceedings},
  year={2018},
}


@inproceedings{baker2019emergent,
  title={Emergent tool use from multi-agent autocurricula},
  author={Baker, Bowen and Kanitscheider, Ingmar and Markov, Todor and Wu, Yi and Powell, Glenn and McGrew, Bob and Mordatch, Igor},
  booktitle={International Conference on Learning Representations},
  year={2019}
}


@inproceedings{samvelyan2019starcraft,
author = {Samvelyan, Mikayel and Rashid, Tabish and Schroeder de Witt, Christian and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim G. J. and Hung, Chia-Man and Torr, Philip H. S. and Foerster, Jakob and Whiteson, Shimon},
title = {The StarCraft Multi-Agent Challenge},
year = {2019},
booktitle = {Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
}

@book{elo1978rating,
  author = {Elo, Arpad E.},
  publisher = {Ishi press international},
  title = {The rating of chessplayers, past and present},
  year = 1978
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
   
  year={2015},
  organization={PMLR}
}

@article{TampuuDqnIQL,
    author = {Tampuu, Ardi AND Matiisen, Tambet AND Kodelja, Dorian AND Kuzovkin, Ilya AND Korjus, Kristjan AND Aru, Juhan AND Aru, Jaan AND Vicente, Raul},
    journal = {PLOS ONE},
    title = {Multiagent cooperation and competition with deep reinforcement learning},
    year = {2017},
}

@article{schulman2017ppo,
  title={Proximal Policy Optimization Algorithms}, 
  author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  year={2017},
  journal={arXiv:1707.06347},
}

@article{wolpert2001optimal,
  title={Optimal payoff functions for members of collectives},
  author={Wolpert, David H. and Tumer, Kagan},
  journal={Advances in Complex Systems},
   
   
   
  year={2001},
}
@article{hasselt2010double,
  title={Double {Q}-learning},
  author={Van Hasselt, Hado},
  journal={Advances in neural information processing systems},
   
  year={2010}
}

@article{THEATE2023199,
title = {Distributional reinforcement learning with unconstrained monotonic neural networks},
journal = {Neurocomputing},
 
 
year = {2023},
author = {Thibaut Th{\'{e}}ate and Antoine Wehenkel and Adrien Bolland and Gilles Louppe and Damien Ernst},
}

@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
   
  year={2017},
  organization={PMLR}
}


@inproceedings{van2016deep,
  title={Deep reinforcement learning with double {Q}-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  year={2016}
}
@inproceedings{
leroy2023impmarl,
title={{IMP}-{MARL}: a Suite of Environments for Large-scale Infrastructure Management Planning via {MARL}},
author={Pascal Leroy and Pablo G. Morato and Jonathan Pisane and Athanasios Kolios and Damien Ernst},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023},
}


@inproceedings{10.5555/2074022.2074088,
author = {Weaver, Lex and Tao, Nigel},
title = {The Optimal Reward Baseline for Gradient-Based Reinforcement Learning},
year = {2001},
booktitle = {Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence},
 
}

@inproceedings{yoo2003slurm,
  title={Slurm: Simple linux utility for resource management},
  author={Yoo, Andy B. and Jette, Morris A. and Grondona, Mark},
  booktitle={Job Scheduling Strategies for Parallel Processing: 9th International Workshopmorato2022syst},
   
  year={2003},
  organization={Springer}
}


@article{nguyen2022weighted,
  title={{Weighted-QMIX-based} optimization for maintenance decision-making of multi-component systems},
  author={Nguyen, Van-Thai and Do, Phuc and Voisin, Alexandre and Iung, Benoit},
  journal={PHM Society European Conference},
   
   
   
  year={2022}
}


@inproceedings{zhang2019cityflow,
  title={{CityFlow}: A multi-agent reinforcement learning environment for large scale city traffic scenario},
  author={Zhang, Huichu and Feng, Siyuan and Liu, Chang and Ding, Yaoyao and Zhu, Yichen and Zhou, Zihan and Zhang, Weinan and Yu, Yong and Jin, Haiming and Li, Zhenhui},
  booktitle={The world wide web conference},
   
  year={2019}
}

@article{KAELBLING199899,
title = {Planning and acting in partially observable stochastic domains},
journal = {Artificial Intelligence},
year = {1998},
author = {Leslie Pack Kaelbling and Michael L. Littman and Anthony R. Cassandra},
}
@article{
lambrechts2022recurrent,
title={Recurrent networks, hidden states and beliefs in partially observable environments},
author={Gaspard Lambrechts and Adrien Bolland and Damien Ernst},
journal={Transactions on Machine Learning Research},
year={2022},
}
@article{chang2003all,
  title={All learning is local: Multi-agent learning in global reward games},
  author={Chang, Yu-Han and Ho, Tracey and Kaelbling, Leslie},
  journal={Advances in neural information processing systems},
   
  year={2003}
}

@article{mohanty2020flatland,
  title={{Flatland-RL }: Multi-agent reinforcement learning on trains},
  author={Mohanty, Sharada and Nygren, Erik and Laurent, Florian and Schneider, Manuel and Scheller, Christian and Bhattacharya, Nilabha and Watson, Jeremy and Egli, Adrian and Eichenberger, Christian and Baumberger, Christian and others},
   journal={arXiv:2012.05893},
  year={2020}
}


@inproceedings{NEURIPS2022_b2a1c152,
 author = {Pan, Xuehai and Liu, Mickel and Zhong, Fangwei and Yang, Yaodong and Zhu, Song-Chun and Wang, Yizhou},
 booktitle = {Advances in Neural Information Processing Systems},
  
 title = {{MATE}: Benchmarking Multi-Agent Reinforcement Learning in Distributed Target Coverage Control},
  
 year = {2022}
}

@inproceedings{papoudakis2021benchmarking,
   title={Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks},
   author={Georgios Papoudakis and Filippos Christianos and Lukas Sch{\"a}fer and Stefano V. Albrecht},
   booktitle = {Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks (NeurIPS)},
   year={2021},
}

@inproceedings{christianos2020shared,
 author = {Christianos, Filippos and Sch\"{a}fer, Lukas and Albrecht, Stefano},
 booktitle = {Advances in Neural Information Processing Systems},
  
 title = {Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning},
  
 year = {2020}
}

@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
   
   
   
  year={2018},
  publisher={American Association for the Advancement of Science}
}


@article{vinyals2017starcraft,
  title={{StarCraft II}: A New Challenge for Reinforcement Learning}, 
  author={Oriol Vinyals and Timo Ewalds and Sergey Bartunov and Petko Georgiev and Alexander Sasha Vezhnevets and Michelle Yeo and Alireza Makhzani and Heinrich K√ºttler and John Agapiou and Julian Schrittwieser and John Quan and Stephen Gaffney and Stig Petersen and Karen Simonyan and Tom Schaul and Hado Van Hasselt and David Silver and Timothy Lillicrap and Kevin Calderone and Paul Keet and Anthony Brunasso and David Lawrence and Anders Ekermo and Jacob Repp and Rodney Tsing},
  year={2017},
  journal={arXiv:1708.04782},
}


@article{vinyals2019grandmaster,
  title={Grandmaster level in {StarCraft II} using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
   
   
   
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@article{konda1999actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay and Tsitsiklis, John},
  journal={Advances in neural information processing systems},
   
  year={1999}
}


@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Reinforcement learning},
   
  year={1992},
  publisher={Springer}
}

@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
   
  year={1999}
}


@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
   
  year={2017}
}

@inproceedings{kurach2020google,
  title={Google research football: A novel reinforcement learning environment},
  author={Kurach, Karol and Raichuk, Anton and Sta{\'n}czyk, Piotr and Zaj{\k{a}}c, Micha{\l} and Bachem, Olivier and Espeholt, Lasse and Riquelme, Carlos and Vincent, Damien and Michalski, Marcin and Bousquet, Olivier and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
   
   
  year={2020}
}

@article{de2020independent,
  title={Is independent learning all you need in the starcraft multi-agent challenge?},
  author={De Witt, Christian Schroeder and Gupta, Tarun and Makoviichuk, Denys and Makoviychuk, Viktor and Torr, Philip HS and Sun, Mingfei and Whiteson, Shimon},
  journal={ arXiv:2011.09533},
  year={2020}
}

@article{ehrgott2012vilfredo,
  title={Vilfredo Pareto and multi-objective optimization},
  author={Ehrgott, Matthias},
  journal={Doc. math},
   
   
  year={2012}
}


@article{Bard_2020,
title = {{The Hanabi challenge: A new frontier for AI research}},
journal = {Artificial Intelligence},
 
 
year = {2020},
author = {Nolan Bard and Jakob N. Foerster and Sarath Chandar and Neil Burch and Marc Lanctot and H. Francis Song and Emilio Parisotto and Vincent Dumoulin and Subhodeep Moitra and Edward Hughes and Iain Dunning and Shibl Mourad and Hugo Larochelle and Marc G. Bellemare and Michael Bowling},
}

@article{SHAVANDI2022118124,
title = {A multi-agent deep reinforcement learning framework for algorithmic trading in financial markets},
journal = {Expert Systems with Applications},
 
 
year = {2022},
author = {Ali Shavandi and Majid Khedmati},
}

@article{poker,
author = {Noam Brown and Tuomas Sandholm},
title = {Superhuman AI for heads-up no-limit poker: Libratus beats top professionals},
journal = {Science},
 
 
 
year = {2018}
}

@article{nash1950equilibrium,
  title={Equilibrium points in n-person games},
  author={Nash Jr, John F},
  journal={Proceedings of the national academy of sciences},
   
   
   
  year={1950},
  publisher={National Acad Sciences}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
   
   
   
  year={2017},
  publisher={Nature Publishing Group}
}



@article{dinneweth2022multi,
  title={Multi-agent reinforcement learning for autonomous vehicles: A survey},
  author={Dinneweth, Joris and Boubezoul, Abderrahmane and Mandiau, Ren{\'e} and Espi{\'e}, St{\'e}phane},
  journal={Autonomous Intelligent Systems},
   
   
   
  year={2022},
  publisher={Springer}
}


@article{stratego,
author = {Julien Perolat  and Bart De Vylder  and Daniel Hennes  and Eugene Tarassov  and Florian Strub  and Vincent de Boer  and Paul Muller  and Jerome T. Connor  and Neil Burch  and Thomas Anthony  and Stephen McAleer  and Romuald Elie  and Sarah H. Cen  and Zhe Wang  and Audrunas Gruslys  and Aleksandra Malysheva  and Mina Khan  and Sherjil Ozair  and Finbarr Timbers  and Toby Pohlen  and Tom Eccles  and Mark Rowland  and Marc Lanctot  and Jean-Baptiste Lespiau  and Bilal Piot  and Shayegan Omidshafiei  and Edward Lockhart  and Laurent Sifre  and Nathalie Beauguerlange  and Remi Munos  and David Silver  and Satinder Singh  and Demis Hassabis  and Karl Tuyls },
title = {Mastering the game of Stratego with model-free multiagent reinforcement learning},
journal = {Science},
 
 
 
year = {2022},
}

@article{jaderberg2017population,
  title={Population based training of neural networks},
  author={Jaderberg, Max and Dalibard, Valentin and Osindero, Simon and Czarnecki, Wojciech M and Donahue, Jeff and Razavi, Ali and Vinyals, Oriol and Green, Tim and Dunning, Iain and Simonyan, Karen and others},
  journal={ arXiv:1711.09846},
  year={2017}
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
   
   
   
  year={2020},
  publisher={Nature Publishing Group UK London}
}


@article{tesauro1994td,
  title={{TD-Gammon}, a self-teaching backgammon program, achieves master-level play},
  author={Tesauro, Gerald},
  journal={Neural computation},
   
   
   
  year={1994},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~‚Ä¶}
}

@article{NIPS1999_464d828b,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
   
   
  year={1999}
}

@book{DecPomdp,
  title={A concise introduction to decentralized POMDPs},
  author={Oliehoek, Frans A. and Amato, Christopher},
   
  year={2016},
  publisher={Springer}
}

@inproceedings{leroy2022twoteam,
title={Value-based {CTDE} Methods in Symmetric Two-team Markov Game: from Cooperation to Team Competition},
author={Leroy, Pascal and Pisane, Jonathan and Ernst, Damien},
booktitle={Deep Reinforcement Learning Workshop NeurIPS 2022},
year={2022}
}

@article{wierstra2010recurrent,
  title={Recurrent policy gradients},
  author={Wierstra, Daan and F{\"o}rster, Alexander and Peters, Jan and Schmidhuber, J{\"u}rgen},
  journal={Logic Journal of IGPL},
   
   
   
  year={2010},
  publisher={Oxford University Press}
}


@article{Hausknecht2015DeepMDPs,
    title = {{Deep recurrent {Q}-learning for partially observable MDPs}},
    year = {2015},
    journal = {AAAI Fall Symposium Series},
    author = {Hausknecht, Matthew and Stone, Peter}
}

@article{rashid2020weighted,
 author = {Rashid, Tabish and Farquhar, Gregory and Peng, Bei and Whiteson, Shimon},
 journal = {Advances in Neural Information Processing Systems},
  
 title = {{Weighted QMIX}: Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning},
  
 year = {2020}
}


@inproceedings{
wang2021qplex,
title={{QPLEX}: Duplex Dueling Multi-Agent {Q}-Learning},
author={Jianhao Wang and Zhizhou Ren and Terry Liu and Yang Yu and Chongjie Zhang},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{Hochreiter1997LongMemory,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
   
   
   
  year={1997},
  publisher={MIT Press}
}
@article{jaderberg2019human,
  title={Human-level performance in 3D multiplayer games with population-based reinforcement learning},
  author={Jaderberg, Max and Czarnecki, Wojciech M and Dunning, Iain and Marris, Luke and Lever, Guy and Castaneda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C and Morcos, Ari S and Ruderman, Avraham and others},
  journal={Science},
   
   
   
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{balduzzi2018re,
  title={Re-evaluating evaluation},
  author={Balduzzi, David and Tuyls, Karl and Perolat, Julien and Graepel, Thore},
  journal={Advances in Neural Information Processing Systems (NIPS)},
  year={2018}
}


@inproceedings{Chung2014EmpiricalModeling,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={NIPS Workshop on Deep Learning},
  year={2014}
}

@article{kitano1997robocup,
  title={RoboCup: A challenge problem for {AI}},
  author={Kitano, Hiroaki and Asada, Minoru and Kuniyoshi, Yasuo and Noda, Itsuki and Osawa, Eiichi and Matsubara, Hitoshi},
  journal={AI magazine},
  year={1997}
}



@inproceedings{robot_soccer,
  title={Solving multi-agent decision problems modeled as dec-pomdp: A robot soccer case study},
  author={A{\c{s}}{\i}k, Okan and Ak{\i}n, H Levent},
  booktitle={Robot Soccer World Cup},
   
  year={2012},
  organization={Springer}
}


@article{zhao2019multiagent,
  title={On multi-agent learning in team sports games}, 
  author={Yunqi Zhao and Igor Borovikov and Jason Rupert and Caedmon Somers and Ahmad Beirami},
  year={2019},
  journal={Proceedings of the 36th International Conference on Machine Learning}
}

@inproceedings{Tan1993,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  booktitle={Proceedings of the Tenth International Conference on machine learning},
   
  year={1993}
}



@article{yang2020qatten,
  title={Qatten: A general framework for cooperative multiagent reinforcement learning},
  author={Yang, Yaodong and Hao, Jianye and Liao, Ben and Shao, Kun and Chen, Guangyong and Liu, Wulong and Tang, Hongyao},
  year={2020},
  journal={arXiv:2002.03939}
}

@inproceedings{
bansal2018emergent,
title={Emergent Complexity via Multi-Agent Competition},
author={Trapit Bansal and Jakub Pachocki and Szymon Sidor and Ilya Sutskever and Igor Mordatch},
booktitle={International Conference on Learning Representations},
year={2018},
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  journal={Nature},
   
   
   
  year={2016},
  publisher={Nature Publishing Group}
}


@article{campbell2002deep,
  title={Deep blue},
  author={Campbell, Murray and Hoane Jr, A Joseph and Hsu, Feng-hsiung},
  journal={Artificial intelligence},
   
   
   
  year={2002},
  publisher={Elsevier}
}


@article{leroy2020qvmix,
  title={Q{V}{M}ix and {Q}{V}{M}ix-{M}ax: extending the deep quality-value family of algorithms to cooperative multi-agent reinforcement learning},
  author={Leroy, Pascal and Ernst, Damien and Geurts, Pierre and Louppe, Gilles and Pisane, Jonathan and Sabatelli, Matthia},
  journal={AAAI-21 Workshop on Reinforcement Learning in Games},
  year={2021}
}

@article{Son2019QTRAN:Learning,
    title={Q{T}{R}{A}{N}: Learning to factorize with transformation for cooperative multi-agent reinforcement learning},
    year = {2019},
    author = {Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
    journal={Proceedings of the 36th International Conference on Machine Learning}
}

@article{Rashid2018,
  title = {{QMIX}: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning},
  author = {Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal = 	 {Proceedings of the 35th International Conference on Machine Learning},
   
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
   
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
}

@article{claus1998dynamics,
  title={The dynamics of reinforcement learning in cooperative multiagent systems},
  author={Claus, Caroline and Boutilier, Craig},
  journal={AAAI},
   
   
   
  year={1998}
}

@article{Ha2016HyperNetworks,
    title = {{HyperNetworks}},
    year = {2016},
    author = {Ha, David and Dai, Andrew and Le, Quoc V.},
    journal = {5th International Conference on Learning Representations}
}

@inproceedings{greenwald2003correlated,
  title={Correlated {Q}-learning},
  author={Greenwald, Amy and Hall, Keith and Serrano, Roberto and others},
  booktitle={ICML},
   
   
  year={2003}
}


@article{hu2003nash,
  title={Nash {Q}-learning for general-sum stochastic games},
  author={Hu, Junling and Wellman, Michael P},
  journal={Journal of machine learning research},
   
   
   
  year={2003}
}

@article{Mahajan2019MAVEN:Exploration,
 author = {Mahajan, Anuj and Rashid, Tabish and Samvelyan, Mikayel and Whiteson, Shimon},
 journal = {Advances in Neural Information Processing Systems},
 title = {{MAVEN}: Multi-Agent Variational Exploration},
  
 year = {2019}
}


@incollection{MarkovGames,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine learning proceedings},
  year={1994},
  publisher={Elsevier}
}


@misc{towers_gymnasium_2023,
        title = {Gymnasium},
        publisher = {Zenodo},
        author = {Towers, Mark and Terry, Jordan K. and Kwiatkowski, Ariel and Balis, John U. and Cola, Gianluca de and Deleu, Tristan and Goul{\~a}o, Manuel and Kallinteris, Andreas and KG, Arjun and Krimmel, Markus and Perez-Vicente, Rodrigo and Pierr{\'e}, Andrea and Schulhoff, Sander and Tai, Jun Jet and Shen, Andrew Tan Jin and Younis, Omar G.},
        year = {2023},
        doi = {10.5281/zenodo.8127026},
}

@article{hu2022marllib,
      title={{MARLlib}: A Scalable Multi-agent Reinforcement Learning Library},
      author={Hu, Siyi and Zhong, Yifan and Gao, Minquan and Wang, Weixun and Dong, Hao and Li, Zhihui and Liang, Xiaodan and Chang, Xiaojun and Yang, Yaodong},
      journal={ arXiv:2210.13708},
      year={2022}
}

@article{huang2022cleanrl,
  author  = {Shengyi Huang and Rousslan Fernand Julien Dossa and Chang Ye and Jeff Braga and Dipam Chakraborty and Kinal Mehta and Jo{\~{a}}o G.M. Ara{\'{u}}jo},
  title   = {{CleanRL}: High-quality Single-file Implementations of Deep Reinforcement Learning Algorithms},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
   
   
   
}

@inproceedings{hong_rethinkigm,
 author = {Hong, Yitian and Jin, Yaochu and Tang, Yang},
 booktitle = {Advances in Neural Information Processing Systems},
  
 title = {Rethinking Individual Global Max in Cooperative Multi-Agent Reinforcement Learning},
  
 year = {2022}
}


@article{yu2022surprising,
  title={The surprising effectiveness of ppo in cooperative multi-agent games},
  author={Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  journal={Advances in Neural Information Processing Systems},
   
   
  year={2022}
}


@article{mirhoseini2021graph,
  title={A graph placement methodology for fast chip design},
  author={Mirhoseini, Azalia and Goldie, Anna and Yazgan, Mustafa and Jiang, Joe Wenjie and Songhori, Ebrahim and Wang, Shen and Lee, Young-Joon and Johnson, Eric and Pathak, Omkar and Nazi, Azade and others},
  journal={Nature},
   
   
   
  year={2021},
  publisher={Nature Publishing Group}
}

@inproceedings{
jang2017categorical,
title={Categorical Reparameterization with Gumbel-Softmax},
author={Eric Jang and Shixiang Gu and Ben Poole},
booktitle={International Conference on Learning Representations},
year={2017},
}


@article{shannon1950,
  title={Programming a computer for playing chess},
  author={Shannon, Claude E},
  journal={The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
   
   
   
  year={1950},
  publisher={Taylor \& Francis}
}

@book{deisenroth2020mathematics,
  title={Mathematics for machine learning},
  author={Deisenroth, Marc Peter and Faisal, A Aldo and Ong, Cheng Soon},
  year={2020},
  publisher={Cambridge University Press}
}

@article{terry2021pettingzoo,
  title={Pettingzoo: Gym for multi-agent reinforcement learning},
  author={Terry, J and Black, Benjamin and Grammel, Nathaniel and Jayakumar, Mario and Hari, Ananth and Sullivan, Ryan and Santos, Luis S and Dieffendahl, Clemens and Horsch, Caroline and Perez-Vicente, Rodrigo and others},
  journal={Advances in Neural Information Processing Systems},
   
   
  year={2021}
}

@inproceedings{
wen2022multiagent,
title={Multi-Agent Reinforcement Learning is a Sequence Modeling Problem},
author={Muning Wen and Jakub Grudzien Kuba and Runji Lin and Weinan Zhang and Ying Wen and Jun Wang and Yaodong Yang},
booktitle={Advances in Neural Information Processing Systems},
year={2022},
}


@article{lauriere2022learning,
  title={Learning mean field games: A survey},
  author={Lauri{\`e}re, Mathieu and Perrin, Sarah and Geist, Matthieu and Pietquin, Olivier},
  journal={arXiv:2205.12944},
  year={2022}
}
